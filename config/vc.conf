{
	"train":{
		"batch_size": 4,
		"epoch": 100,
		"log_every": 100,
		"discriminator_start": 5000
	},
	"val":{
		"batch_size": 4
	},
	"model":{
		"encoder":{
			"dil_conv":{
				"conv_type": "linear",
				"n_convs": 2,
				"in_dim": 55,
				"kernel_size": 3
			},
			"rnn": {
				"rnn_type": "gru",
				"model_arch": "rnn",
				"h_units": 1024,
				"n_layers": 1,
				"bidirectional": 0,
				"out_dim": 64
			}
		},
		"decoder":{
                        "dil_conv":{
                                "conv_type": "linear",
                                "n_convs": 2,
                                "in_dim": 34,
                                "kernel_size": 3
                        },
                        "rnn": {
                                "rnn_type": "gru",
				"model_arch": "rnn",
                                "h_units": 1024,
                                "n_layers": 1,
                                "bidirectional": 0,
				"out_dim": 50
                        }
		},
		"generator":{
			"in_channels": 1,
			"out_channels": 1,
			"aux_channels": 50,
			"aux_context_window": 0
		},
		"discriminator":{
			"in_channels": 1,
			"out_channels": 1
		}
	},
	"optim":{
                "method": "adam",
                "learning_rate": 0.0001,
                "max_grad_norm": 50,
                "lr_decay": 1,
                "decay_steps": "None",
                "start_decay_steps": "None",
                "beta1": 0.9,
                "beta2": 0.999,
                "adagrad_accum":0.0,
                "decay_method": "None",
                "warmup_steps": 2000,
                "weight_decay": "None"
        },
	"gen_optim":{
		"method": "adam",
		"learning_rate": 0.0001,
		"max_grad_norm": 50,
		"lr_decay": 1,
		"decay_steps": "None",
		"start_decay_steps": "None",
		"beta1": 0.9,
		"beta2": 0.98,
		"adagrad_accum":0.0,
		"decay_method": "None",
		"warmup_steps": 2000,
		"weight_decay": "None"
	},
	"dis_optim":{
                "method": "adam",
                "learning_rate": 0.0001,
                "max_grad_norm": 50,
                "lr_decay": 1,
                "decay_steps": "None",
                "start_decay_steps": "None",
                "beta1": 0.9,
                "beta2": 0.98,
                "adagrad_accum":0.0,
                "decay_method": "None",
                "warmup_steps": 2000,
                "weight_decay": "None"
        }

}
